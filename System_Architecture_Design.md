# System Architecture: Generator-Retriever-Verifier Pipeline

This document outlines the architectural design for the hallucination detection and mitigation system, as per the project plan. The pipeline is composed of three main modules: the Generator, the Retriever, and the Verifier. The process is designed to be iterative, inspired by methodologies like Chain-of-Verification (CoVe) and Self-RAG.

---

## 1. Visual Workflow Diagram (Mermaid)

```mermaid
graph TD
    A[User Query] --> B{Generator (Draft)};
    B --> C{Verifier (Planner)};
    C -- Extracts Atomic Claims --> D[Claim 1, Claim 2, ...];
    D --> E{Verifier (Planner)};
    E -- Generates Verification Questions --> F[Q1 for Claim 1, Q2 for Claim 2, ...];
    F --> G{Retriever};
    G -- Retrieves Evidence from Vector DB --> H[Evidence 1 for Q1, Evidence 2 for Q2, ...];
    
    subgraph Verifier (Execution & Scoring)
        I[Evidence Scorer]
        J[NLI Contradiction Detector]
        K[Uncertainty Module]
    end

    H --> I;
    H --> J;
    B --> K;

    subgraph For Each Claim
        D -- Claim --> I;
        D -- Claim --> J;
        D -- Claim --> K;
    end

    I -- Evidence Score --> L[Ensemble Verifier];
    J -- NLI Score (Supported/Refuted) --> L;
    K -- Uncertainty Score --> L;

    L -- Verification Results (Claim, Score, Evidence) --> M{Mitigation Logic};
    B -- Original Draft --> M;
    
    M -- Decision --> N[Final Verified Response];
    N -- Includes Citations & Warnings --> O[Output to User];

    style A fill:#d4edda,stroke:#155724
    style O fill:#d4edda,stroke:#155724
    style B fill:#cce5ff,stroke:#004085
    style G fill:#cce5ff,stroke:#004085
    style L fill:#fff3cd,stroke:#856404
    style M fill:#f8d7da,stroke:#721c24
```

---

## 2. Module Inputs and Outputs

### Module 1: Generator
The Generator is a pre-trained Large Language Model (LLM) responsible for creating the initial text.

-   **Process:** Generates a draft response to the user's query. This initial response is not yet verified and may contain hallucinations.
-   **Inputs:**
    -   `user_query`: (string) The input prompt from the user.
-   **Outputs:**
    -   `draft_response`: (string) The initial, unverified answer generated by the LLM.
    -   `generation_metadata`: (object) Optional metadata, including token probabilities or log-likelihoods if accessible, which can be used by the Uncertainty Module.

### Module 2: Retriever
The Retriever fetches relevant documents from a knowledge source to be used as evidence.

-   **Process:** Based on questions formulated by the Verifier, the Retriever queries a vector database (e.g., FAISS) containing the indexed knowledge corpus (e.g., Wikipedia). It employs a hybrid search combining dense and sparse retrieval methods.
-   **Inputs:**
    -   `verification_questions`: (list of strings) A list of precise questions aimed at fact-checking the claims made in the `draft_response`.
-   **Outputs:**
    -   `retrieved_evidence_set`: (list of objects) A list where each object corresponds to a verification question and contains:
        -   `question`: (string) The original verification question.
        -   `evidence_chunks`: (list of objects) A ranked list of the top-k retrieved text chunks, each with:
            -   `content`: (string) The text of the evidence chunk.
            -   `source_id`: (string) A unique identifier for the source document (e.g., Wikipedia page ID).
            -   `retrieval_score`: (float) The relevance score from the retrieval system.

### Module 3: Verifier
The Verifier is the core innovation of this project. It's an ensemble module with two main phases: Planning and Execution/Scoring.

#### 3.1 Verifier (Planning Phase)
-   **Process:** Deconstructs the `draft_response` to prepare for verification. This is inspired by the planning step in the Chain-of-Verification paper.
-   **Inputs:**
    -   `draft_response`: (string) The initial text from the Generator.
-   **Outputs:**
    -   `atomic_claims`: (list of strings) A list of individual, verifiable statements extracted from the draft.
    -   `verification_questions`: (list of strings) A list of questions generated from the atomic claims, designed to be answerable by the Retriever.

#### 3.2 Verifier (Execution & Scoring Phase)
-   **Process:** This phase involves the ensemble of sub-modules that analyze each claim against the retrieved evidence and the model's own uncertainty.
-   **Inputs:**
    -   `atomic_claims`: (list of strings) From the planning phase.
    -   `retrieved_evidence_set`: (list of objects) From the Retriever.
    -   `draft_response` / `generation_metadata`: (string/object) From the Generator, for the uncertainty analysis.
-   **Sub-Modules & Their Outputs:**
    1.  **Evidence Scorer:**
        -   **Process:** Scores the relevance of each retrieved evidence chunk to its corresponding claim.
        -   **Output:** `evidence_alignment_score` (float) for each claim-evidence pair.
    2.  **NLI Contradiction Detector:**
        -   **Process:** Uses a fine-tuned NLI model (e.g., DeBERTa) to compare each claim against its top-ranked evidence.
        -   **Output:** `nli_label` (enum: `Supported`, `Refuted`, `Not Enough Info`) and `nli_score` (float) for each claim-evidence pair.
    3.  **Uncertainty Module:**
        -   **Process:** Calculates a confidence score for each claim based on the Generator's behavior, using techniques from SelfCheckGPT (e.g., sampling multiple generations and measuring consistency/disagreement).
        -   **Output:** `uncertainty_score` (float) for each claim.
-   **Final Output of Verifier:**
    -   `verification_results`: (list of objects) A comprehensive list where each object represents a claim and its verification status:
        -   `claim`: (string) The atomic claim being verified.
        -   `is_supported`: (boolean) A final judgment based on the ensemble scores.
        -   `confidence_score`: (float) The verifier's overall confidence in the claim's factuality.
        -   `supporting_evidence`: (object) The best piece of evidence found, including its content and source ID.
        -   `issues_detected`: (list of strings) e.g., ["Contradiction found", "High uncertainty"].

### Module 4: Mitigation Logic
This final module revises the draft based on the verifier's output.

-   **Process:** Iterates through the `verification_results`. It rewrites the `draft_response`, corrects factual errors, removes unsupported claims, and appends citations. For claims that are plausible but unverified, it can attach a warning.
-   **Inputs:**
    -   `draft_response`: (string) The original generated text.
    -   `verification_results`: (list of objects) The detailed output from the Verifier.
-   **Outputs:**
    -   `final_response`: (string) The polished, verified, and cited response to be presented to the user. It may include in-line warnings (e.g., "[Warning: This claim could not be verified]") for transparency.
